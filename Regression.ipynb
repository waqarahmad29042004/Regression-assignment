{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "    Answer:Simple Linear Regression is a statistical method used to model the relationship between one independent variable (X) and one dependent variable (Y) using a straight-line equation:\n",
        "\n",
        "    Y=mX+c\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "    Answer:Linearity\n",
        "\n",
        "    Independence of errors\n",
        "\n",
        "    Homoscedasticity (constant variance of errors)\n",
        "\n",
        "    Normality of residuals\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "    Answer:The coefficient m represents the slope of the line. It shows how much Y changes for a one-unit increase in X.\n",
        "\n",
        "4. What does the intercept c represent in the equation Y=mX+c?\n",
        "\n",
        "    Answer:The intercept c represents the value of Y when X equals 0.\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "    Answer:m=∑(X−Xˉ)(Y−Yˉ)​/∑(X−Xˉ)^2\n",
        "\t​\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "    Answer:It minimizes the sum of squared differences between actual and predicted values to find the best-fit line.\n",
        "\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
        "\n",
        "    Answer:R² represents the proportion of variance in the dependent variable explained by the independent variable.\n",
        "\n",
        "8. What is Multiple Linear Regression?\n",
        "\n",
        "    Answer:Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables.\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "    Answer:Simple regression uses one independent variable, while multiple regression uses two or more independent variables.\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "    Answer:Linearity\n",
        "\n",
        "    Independence\n",
        "\n",
        "    Homoscedasticity\n",
        "\n",
        "    Normality of errors\n",
        "\n",
        "    No multicollinearity\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "    Answer:Heteroscedasticity occurs when error variance is not constant. It leads to unreliable standard errors and hypothesis tests.\n",
        "\n",
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "    Answer:Remove correlated variables\n",
        "\n",
        "    Use Ridge or Lasso regression\n",
        "\n",
        "    Apply Principal Component Analysis (PCA)\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "    Answer:One-hot encoding\n",
        "\n",
        "    Label encoding\n",
        "\n",
        "    Dummy variables\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "    Answer:Interaction terms capture the combined effect of two variables on the dependent variable.\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "    Answer:In simple regression, it is Y when X=0. In multiple regression, it is Y when all independent variables equal zero.\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "    Answer:The slope indicates the direction and magnitude of the relationship. It determines how predictions change with X.\n",
        "\n",
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "    Answer:It provides a baseline value of Y when all predictors are zero.\n",
        "\n",
        "18. What are the limitations of using R² as a sole measure of model performance?\n",
        "\n",
        "    Answer:Does not indicate causation\n",
        "\n",
        "    Always increases with more variables\n",
        "\n",
        "    Does not measure prediction accuracy\n",
        "\n",
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "    Answer:It indicates high uncertainty in the coefficient estimate and possibly weak significance.\n",
        "\n",
        "20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "    Answer:It appears as a funnel-shaped pattern in residual plots. It must be addressed to ensure valid statistical inference.\n",
        "\n",
        "21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        "\n",
        "    Answer:It suggests unnecessary variables are included, leading to overfitting.\n",
        "\n",
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "    Answer:Scaling ensures fair comparison of coefficients and improves performance in regularized models.\n",
        "\n",
        "23. What is polynomial regression?\n",
        "\n",
        "    Answer:Polynomial regression models nonlinear relationships by adding polynomial terms of the independent variable.\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "    Answer:Polynomial regression includes higher-degree terms (e.g., X², X³), while linear regression uses only X.\n",
        "\n",
        "25. When is polynomial regression used?\n",
        "\n",
        "    Answer:When the relationship between variables is nonlinear but can be approximated by a polynomial curve.\n",
        "\n",
        "26. What is the general equation for polynomial regression?\n",
        "    Answer:Y=b0 ​+ b1​X + b2​X^2 + b3​X^3 +...+ bn​X^n\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "    Answer:Yes, by including polynomial terms for multiple independent variables.\n",
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "    Answer:    Risk of overfitting\n",
        "\n",
        "    Poor extrapolation\n",
        "\n",
        "    Sensitive to outliers\n",
        "\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "    Answer:Cross-validation\n",
        "\n",
        "    Adjusted R²\n",
        "\n",
        "    AIC/BIC\n",
        "\n",
        "    Residual analysis\n",
        "\n",
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "    Answer:Visualization helps detect nonlinear patterns and choose the appropriate polynomial degree.\n",
        "\n",
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "    Answer:Using PolynomialFeatures from sklearn:\n",
        "\n",
        "    from sklearn.preprocessing import PolynomialFeatures\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.pipeline import make_pipeline\n",
        "\n",
        "    model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "    model.fit(X, y)"
      ],
      "metadata": {
        "id": "Tb0cwczMt6s-"
      }
    }
  ]
}